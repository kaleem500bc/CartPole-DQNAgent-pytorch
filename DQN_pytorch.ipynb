{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQN pytorch",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaleem500bc/CartPole-DQNAgent-pytorch/blob/main/DQN_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLAiMoMUyiki"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import gym\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "import random\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-3wQ9-SfJS3",
        "outputId": "2c341ef4-8174-4784-eae7-6f04aa8099f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# make virtual screen and redirect render to this screen\n",
        "# From https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh\n",
        "!wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
        "!bash ../xvfb start\n",
        "os.environ['DISPLAY'] = ':1'"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting virtual X frame buffer: Xvfb.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iLj1NL7n64P"
      },
      "source": [
        "class Agent:\n",
        "  def __init__(self,state_size, action_size):\n",
        "    self.state_size = state_size\n",
        "    self.action_size = action_size\n",
        "    self.memory = deque(maxlen=2000)\n",
        "    self.gamma = 0.95\n",
        "    self.epsilon = 1.0\n",
        "    self.epsilon_decay = 0.995\n",
        "    self.epsilon_min = 0.01\n",
        "    self.learning_rate = 0.001\n",
        "    self.model = self.create_model()\n",
        "    self.optimizer = torch.optim.Adam(self.model.parameters())\n",
        "    self.criterion = nn.MSELoss()\n",
        "\n",
        "  # Model that will learn the Q-function/ Agent that will play the game\n",
        "  def create_model(self):\n",
        "    model = nn.Sequential(\n",
        "        nn.Linear(self.state_size,256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128,64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(64,self.action_size)\n",
        "    )\n",
        "    model.to(\"cuda\")\n",
        "    return model\n",
        "    \n",
        "  # Replay memory where different episode will be store\n",
        "  def replay_buffer(self, state,action, reward, next_state, done):\n",
        "    state = torch.tensor(state,dtype=torch.float).to(\"cuda\")\n",
        "    action = torch.tensor(action,dtype=torch.float).to(\"cuda\")\n",
        "    reward = torch.tensor(reward,dtype=torch.float).to(\"cuda\")\n",
        "    next_state = torch.tensor(next_state,dtype=torch.float).to(\"cuda\")\n",
        "    \n",
        "    self.memory.append((state,action, reward, next_state,done))\n",
        "  \n",
        "  # Get action that the agent should take\n",
        "  def action(self, state):\n",
        "\n",
        "    if np.random.rand() <= self.epsilon:\n",
        "      # Random exploration\n",
        "      return random.randrange(self.action_size)\n",
        "\n",
        "    # Get action from the agent/ exploitation\n",
        "    state = state.to(\"cuda\")\n",
        "    act_values = self.model(state)\n",
        "    return int(torch.argmax(act_values).item())\n",
        "\n",
        "\n",
        "  # Train the model according to q-learning\n",
        "  def training(self,batch_size, training_iter):\n",
        "    print(\"Training Iteration: \", training_iter)\n",
        "    minibatch = random.sample(self.memory, batch_size)\n",
        "    for state,action, reward, next_state,done in minibatch:\n",
        "      actual_reward = reward\n",
        "      state = state.to(\"cuda\")\n",
        "      next_state = next_state.to(\"cuda\")\n",
        "\n",
        "      predicted_reward = self.model(state)\n",
        "      predicted_reward = predicted_reward[int(action.item())] \n",
        "      if not done:\n",
        "        actual_reward = reward + self.gamma * torch.amax(\n",
        "            self.model(next_state)\n",
        "            )\n",
        "        \n",
        "        self.optimizer.zero_grad()\n",
        "    \n",
        "        loss = self.criterion(predicted_reward,actual_reward)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "      else:\n",
        "        self.optimizer.zero_grad()\n",
        "        loss = self.criterion(predicted_reward, actual_reward)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "    if self.epsilon > self.epsilon_min:\n",
        "      self.epsilon *= self.epsilon_decay\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HM99c53wrs2",
        "outputId": "f491bf03-f0ee-47b4-ae5e-13e32d47ad3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "env = gym.make(\"CartPole-v0\").env\n",
        "obs = env.reset()\n",
        "plt.imshow(env.render(\"rgb_array\"))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fcbc0037a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1NTH6CcvzJR",
        "outputId": "261d8aaf-90c5-4169-b2f2-4aed7f248c0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "state_size = env.observation_space.shape[0]\n",
        "action_size = env.action_space.n\n",
        "agent = Agent(state_size, action_size)\n",
        "agent"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.Agent at 0x7fcbc01a6c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuBXbUI41kiY"
      },
      "source": [
        "def populate_replayBuffer(agent,env, n_episode):\n",
        "  done = False\n",
        "  batch_size = 2000\n",
        "  training_iter = 1\n",
        "  for e in range(n_episode):\n",
        "    state = env.reset()\n",
        "    state = torch.tensor(state,dtype=torch.float)\n",
        "    buffer_size = 5000\n",
        "    for i in range(buffer_size):\n",
        "      action = agent.action(state)\n",
        "      next_state, reward, done, _ = env.step(action)\n",
        "      reward = reward if not done else -10\n",
        "      agent.replay_buffer(state,action,reward,next_state,done)\n",
        "      state = torch.tensor(next_state,dtype=torch.float)\n",
        "\n",
        "      if done:\n",
        "        print(\"episods: {}, score: {}\".format(e,i))\n",
        "        break\n",
        "\n",
        "    if len(agent.memory) >= batch_size:\n",
        "      training_iter += 1\n",
        "      agent.training(batch_size, training_iter)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86xjPeYs9W4b",
        "outputId": "fd03af63-af9a-419f-b6b8-4703612e6355",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "populate_replayBuffer(agent,env,5000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "episods: 0, score: 23\n",
            "episods: 1, score: 17\n",
            "episods: 2, score: 13\n",
            "episods: 3, score: 12\n",
            "episods: 4, score: 17\n",
            "episods: 5, score: 18\n",
            "episods: 6, score: 9\n",
            "episods: 7, score: 15\n",
            "episods: 8, score: 22\n",
            "episods: 9, score: 23\n",
            "episods: 10, score: 17\n",
            "episods: 11, score: 64\n",
            "episods: 12, score: 17\n",
            "episods: 13, score: 12\n",
            "episods: 14, score: 21\n",
            "episods: 15, score: 9\n",
            "episods: 16, score: 14\n",
            "episods: 17, score: 21\n",
            "episods: 18, score: 8\n",
            "episods: 19, score: 18\n",
            "episods: 20, score: 23\n",
            "episods: 21, score: 23\n",
            "episods: 22, score: 10\n",
            "episods: 23, score: 22\n",
            "episods: 24, score: 38\n",
            "episods: 25, score: 39\n",
            "episods: 26, score: 12\n",
            "episods: 27, score: 31\n",
            "episods: 28, score: 14\n",
            "episods: 29, score: 46\n",
            "episods: 30, score: 16\n",
            "episods: 31, score: 25\n",
            "episods: 32, score: 13\n",
            "episods: 33, score: 26\n",
            "episods: 34, score: 17\n",
            "episods: 35, score: 11\n",
            "episods: 36, score: 24\n",
            "episods: 37, score: 17\n",
            "episods: 38, score: 35\n",
            "episods: 39, score: 15\n",
            "episods: 40, score: 17\n",
            "episods: 41, score: 12\n",
            "episods: 42, score: 10\n",
            "episods: 43, score: 40\n",
            "episods: 44, score: 20\n",
            "episods: 45, score: 20\n",
            "episods: 46, score: 17\n",
            "episods: 47, score: 12\n",
            "episods: 48, score: 22\n",
            "episods: 49, score: 17\n",
            "episods: 50, score: 14\n",
            "episods: 51, score: 18\n",
            "episods: 52, score: 32\n",
            "episods: 53, score: 31\n",
            "episods: 54, score: 23\n",
            "episods: 55, score: 16\n",
            "episods: 56, score: 16\n",
            "episods: 57, score: 18\n",
            "episods: 58, score: 36\n",
            "episods: 59, score: 15\n",
            "episods: 60, score: 21\n",
            "episods: 61, score: 11\n",
            "episods: 62, score: 37\n",
            "episods: 63, score: 15\n",
            "episods: 64, score: 15\n",
            "episods: 65, score: 36\n",
            "episods: 66, score: 20\n",
            "episods: 67, score: 18\n",
            "episods: 68, score: 12\n",
            "episods: 69, score: 18\n",
            "episods: 70, score: 16\n",
            "episods: 71, score: 10\n",
            "episods: 72, score: 39\n",
            "episods: 73, score: 10\n",
            "episods: 74, score: 16\n",
            "episods: 75, score: 16\n",
            "episods: 76, score: 51\n",
            "episods: 77, score: 26\n",
            "episods: 78, score: 22\n",
            "episods: 79, score: 20\n",
            "episods: 80, score: 32\n",
            "episods: 81, score: 17\n",
            "episods: 82, score: 26\n",
            "episods: 83, score: 30\n",
            "episods: 84, score: 15\n",
            "episods: 85, score: 11\n",
            "episods: 86, score: 27\n",
            "episods: 87, score: 24\n",
            "episods: 88, score: 26\n",
            "episods: 89, score: 26\n",
            "episods: 90, score: 7\n",
            "episods: 91, score: 21\n",
            "Training Iteration:  2\n",
            "episods: 92, score: 16\n",
            "Training Iteration:  3\n",
            "episods: 93, score: 30\n",
            "Training Iteration:  4\n",
            "episods: 94, score: 17\n",
            "Training Iteration:  5\n",
            "episods: 95, score: 9\n",
            "Training Iteration:  6\n",
            "episods: 96, score: 20\n",
            "Training Iteration:  7\n",
            "episods: 97, score: 10\n",
            "Training Iteration:  8\n",
            "episods: 98, score: 32\n",
            "Training Iteration:  9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Co6B9Wf1AZpb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}