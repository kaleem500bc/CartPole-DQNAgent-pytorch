{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQN pytorch",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaleem500bc/CartPole-DQNAgent-pytorch/blob/main/DQN_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLAiMoMUyiki"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import gym\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "import random\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-3wQ9-SfJS3",
        "outputId": "2c341ef4-8174-4784-eae7-6f04aa8099f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# make virtual screen and redirect render to this screen\n",
        "# From https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh\n",
        "!wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
        "!bash ../xvfb start\n",
        "os.environ['DISPLAY'] = ':1'"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting virtual X frame buffer: Xvfb.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iLj1NL7n64P"
      },
      "source": [
        "class Agent:\n",
        "  def __init__(self,state_size, action_size):\n",
        "    self.state_size = state_size\n",
        "    self.action_size = action_size\n",
        "    self.memory = deque(maxlen=2000)\n",
        "    self.gamma = 0.95\n",
        "    self.epsilon = 1.0\n",
        "    self.epsilon_decay = 0.995\n",
        "    self.epsilon_min = 0.01\n",
        "    self.learning_rate = 0.001\n",
        "    self.model = self.create_model()\n",
        "    self.optimizer = torch.optim.Adam(self.model.parameters())\n",
        "    self.criterion = nn.MSELoss()\n",
        "\n",
        "  # Model that will learn the Q-function/ Agent that will play the game\n",
        "  def create_model(self):\n",
        "    model = nn.Sequential(\n",
        "        nn.Linear(self.state_size,256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128,64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(64,self.action_size)\n",
        "    )\n",
        "    model.to(\"cuda\")\n",
        "    return model\n",
        "    \n",
        "  # Replay memory where different episode will be store\n",
        "  def replay_buffer(self, state,action, reward, next_state, done):\n",
        "    state = torch.tensor(state,dtype=torch.float).to(\"cuda\")\n",
        "    action = torch.tensor(action,dtype=torch.float).to(\"cuda\")\n",
        "    reward = torch.tensor(reward,dtype=torch.float).to(\"cuda\")\n",
        "    next_state = torch.tensor(next_state,dtype=torch.float).to(\"cuda\")\n",
        "    \n",
        "    self.memory.append((state,action, reward, next_state,done))\n",
        "  \n",
        "  # Get action that the agent should take\n",
        "  def action(self, state):\n",
        "\n",
        "    if np.random.rand() <= self.epsilon:\n",
        "      # Random exploration\n",
        "      return random.randrange(self.action_size)\n",
        "\n",
        "    # Get action from the agent/ exploitation\n",
        "    state = state.to(\"cuda\")\n",
        "    act_values = self.model(state)\n",
        "    return int(torch.argmax(act_values).item())\n",
        "\n",
        "\n",
        "  # Train the model according to q-learning\n",
        "  def training(self,batch_size, training_iter):\n",
        "    print(\"Training Iteration: \", training_iter)\n",
        "    minibatch = random.sample(self.memory, batch_size)\n",
        "    for state,action, reward, next_state,done in minibatch:\n",
        "      actual_reward = reward\n",
        "      state = state.to(\"cuda\")\n",
        "      next_state = next_state.to(\"cuda\")\n",
        "\n",
        "      predicted_reward = self.model(state)\n",
        "      predicted_reward = predicted_reward[int(action.item())] \n",
        "      if not done:\n",
        "        actual_reward = reward + self.gamma * torch.amax(\n",
        "            self.model(next_state)\n",
        "            )\n",
        "        \n",
        "        self.optimizer.zero_grad()\n",
        "    \n",
        "        loss = self.criterion(predicted_reward,actual_reward)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "      else:\n",
        "        self.optimizer.zero_grad()\n",
        "        loss = self.criterion(predicted_reward, actual_reward)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "    if self.epsilon > self.epsilon_min:\n",
        "      self.epsilon *= self.epsilon_decay\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HM99c53wrs2",
        "outputId": "f491bf03-f0ee-47b4-ae5e-13e32d47ad3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "env = gym.make(\"CartPole-v0\").env\n",
        "obs = env.reset()\n",
        "plt.imshow(env.render(\"rgb_array\"))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fcbc0037a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1NTH6CcvzJR",
        "outputId": "261d8aaf-90c5-4169-b2f2-4aed7f248c0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "state_size = env.observation_space.shape[0]\n",
        "action_size = env.action_space.n\n",
        "agent = Agent(state_size, action_size)\n",
        "agent"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.Agent at 0x7fcbc01a6c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuBXbUI41kiY"
      },
      "source": [
        "def populate_replayBuffer(agent,env, n_episode):\n",
        "  done = False\n",
        "  batch_size = 2000\n",
        "  training_iter = 1\n",
        "  for e in range(n_episode):\n",
        "    state = env.reset()\n",
        "    state = torch.tensor(state,dtype=torch.float)\n",
        "    buffer_size = 5000\n",
        "    for i in range(buffer_size):\n",
        "      action = agent.action(state)\n",
        "      next_state, reward, done, _ = env.step(action)\n",
        "      reward = reward if not done else -10\n",
        "      agent.replay_buffer(state,action,reward,next_state,done)\n",
        "      state = torch.tensor(next_state,dtype=torch.float)\n",
        "\n",
        "      if done:\n",
        "        print(\"episods: {}, score: {}\".format(e,i))\n",
        "        break\n",
        "\n",
        "    if len(agent.memory) >= batch_size:\n",
        "      training_iter += 1\n",
        "      agent.training(batch_size, training_iter)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86xjPeYs9W4b",
        "outputId": "fd03af63-af9a-419f-b6b8-4703612e6355",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "populate_replayBuffer(agent,env,5000)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "episods: 0, score: 23\n",
            "episods: 1, score: 17\n",
            "episods: 2, score: 13\n",
            "episods: 3, score: 12\n",
            "episods: 4, score: 17\n",
            "episods: 5, score: 18\n",
            "episods: 6, score: 9\n",
            "episods: 7, score: 15\n",
            "episods: 8, score: 22\n",
            "episods: 9, score: 23\n",
            "episods: 10, score: 17\n",
            "episods: 11, score: 64\n",
            "episods: 12, score: 17\n",
            "episods: 13, score: 12\n",
            "episods: 14, score: 21\n",
            "episods: 15, score: 9\n",
            "episods: 16, score: 14\n",
            "episods: 17, score: 21\n",
            "episods: 18, score: 8\n",
            "episods: 19, score: 18\n",
            "episods: 20, score: 23\n",
            "episods: 21, score: 23\n",
            "episods: 22, score: 10\n",
            "episods: 23, score: 22\n",
            "episods: 24, score: 38\n",
            "episods: 25, score: 39\n",
            "episods: 26, score: 12\n",
            "episods: 27, score: 31\n",
            "episods: 28, score: 14\n",
            "episods: 29, score: 46\n",
            "episods: 30, score: 16\n",
            "episods: 31, score: 25\n",
            "episods: 32, score: 13\n",
            "episods: 33, score: 26\n",
            "episods: 34, score: 17\n",
            "episods: 35, score: 11\n",
            "episods: 36, score: 24\n",
            "episods: 37, score: 17\n",
            "episods: 38, score: 35\n",
            "episods: 39, score: 15\n",
            "episods: 40, score: 17\n",
            "episods: 41, score: 12\n",
            "episods: 42, score: 10\n",
            "episods: 43, score: 40\n",
            "episods: 44, score: 20\n",
            "episods: 45, score: 20\n",
            "episods: 46, score: 17\n",
            "episods: 47, score: 12\n",
            "episods: 48, score: 22\n",
            "episods: 49, score: 17\n",
            "episods: 50, score: 14\n",
            "episods: 51, score: 18\n",
            "episods: 52, score: 32\n",
            "episods: 53, score: 31\n",
            "episods: 54, score: 23\n",
            "episods: 55, score: 16\n",
            "episods: 56, score: 16\n",
            "episods: 57, score: 18\n",
            "episods: 58, score: 36\n",
            "episods: 59, score: 15\n",
            "episods: 60, score: 21\n",
            "episods: 61, score: 11\n",
            "episods: 62, score: 37\n",
            "episods: 63, score: 15\n",
            "episods: 64, score: 15\n",
            "episods: 65, score: 36\n",
            "episods: 66, score: 20\n",
            "episods: 67, score: 18\n",
            "episods: 68, score: 12\n",
            "episods: 69, score: 18\n",
            "episods: 70, score: 16\n",
            "episods: 71, score: 10\n",
            "episods: 72, score: 39\n",
            "episods: 73, score: 10\n",
            "episods: 74, score: 16\n",
            "episods: 75, score: 16\n",
            "episods: 76, score: 51\n",
            "episods: 77, score: 26\n",
            "episods: 78, score: 22\n",
            "episods: 79, score: 20\n",
            "episods: 80, score: 32\n",
            "episods: 81, score: 17\n",
            "episods: 82, score: 26\n",
            "episods: 83, score: 30\n",
            "episods: 84, score: 15\n",
            "episods: 85, score: 11\n",
            "episods: 86, score: 27\n",
            "episods: 87, score: 24\n",
            "episods: 88, score: 26\n",
            "episods: 89, score: 26\n",
            "episods: 90, score: 7\n",
            "episods: 91, score: 21\n",
            "Training Iteration:  2\n",
            "episods: 92, score: 16\n",
            "Training Iteration:  3\n",
            "episods: 93, score: 30\n",
            "Training Iteration:  4\n",
            "episods: 94, score: 17\n",
            "Training Iteration:  5\n",
            "episods: 95, score: 9\n",
            "Training Iteration:  6\n",
            "episods: 96, score: 20\n",
            "Training Iteration:  7\n",
            "episods: 97, score: 10\n",
            "Training Iteration:  8\n",
            "episods: 98, score: 32\n",
            "Training Iteration:  9\n",
            "episods: 99, score: 46\n",
            "Training Iteration:  10\n",
            "episods: 100, score: 19\n",
            "Training Iteration:  11\n",
            "episods: 101, score: 13\n",
            "Training Iteration:  12\n",
            "episods: 102, score: 19\n",
            "Training Iteration:  13\n",
            "episods: 103, score: 23\n",
            "Training Iteration:  14\n",
            "episods: 104, score: 28\n",
            "Training Iteration:  15\n",
            "episods: 105, score: 40\n",
            "Training Iteration:  16\n",
            "episods: 106, score: 34\n",
            "Training Iteration:  17\n",
            "episods: 107, score: 9\n",
            "Training Iteration:  18\n",
            "episods: 108, score: 11\n",
            "Training Iteration:  19\n",
            "episods: 109, score: 32\n",
            "Training Iteration:  20\n",
            "episods: 110, score: 36\n",
            "Training Iteration:  21\n",
            "episods: 111, score: 25\n",
            "Training Iteration:  22\n",
            "episods: 112, score: 30\n",
            "Training Iteration:  23\n",
            "episods: 113, score: 39\n",
            "Training Iteration:  24\n",
            "episods: 114, score: 59\n",
            "Training Iteration:  25\n",
            "episods: 115, score: 15\n",
            "Training Iteration:  26\n",
            "episods: 116, score: 15\n",
            "Training Iteration:  27\n",
            "episods: 117, score: 16\n",
            "Training Iteration:  28\n",
            "episods: 118, score: 68\n",
            "Training Iteration:  29\n",
            "episods: 119, score: 16\n",
            "Training Iteration:  30\n",
            "episods: 120, score: 30\n",
            "Training Iteration:  31\n",
            "episods: 121, score: 26\n",
            "Training Iteration:  32\n",
            "episods: 122, score: 84\n",
            "Training Iteration:  33\n",
            "episods: 123, score: 19\n",
            "Training Iteration:  34\n",
            "episods: 124, score: 13\n",
            "Training Iteration:  35\n",
            "episods: 125, score: 32\n",
            "Training Iteration:  36\n",
            "episods: 126, score: 62\n",
            "Training Iteration:  37\n",
            "episods: 127, score: 55\n",
            "Training Iteration:  38\n",
            "episods: 128, score: 34\n",
            "Training Iteration:  39\n",
            "episods: 129, score: 23\n",
            "Training Iteration:  40\n",
            "episods: 130, score: 36\n",
            "Training Iteration:  41\n",
            "episods: 131, score: 83\n",
            "Training Iteration:  42\n",
            "episods: 132, score: 68\n",
            "Training Iteration:  43\n",
            "episods: 133, score: 55\n",
            "Training Iteration:  44\n",
            "episods: 134, score: 29\n",
            "Training Iteration:  45\n",
            "episods: 135, score: 64\n",
            "Training Iteration:  46\n",
            "episods: 136, score: 27\n",
            "Training Iteration:  47\n",
            "episods: 137, score: 13\n",
            "Training Iteration:  48\n",
            "episods: 138, score: 26\n",
            "Training Iteration:  49\n",
            "episods: 139, score: 67\n",
            "Training Iteration:  50\n",
            "episods: 140, score: 36\n",
            "Training Iteration:  51\n",
            "episods: 141, score: 22\n",
            "Training Iteration:  52\n",
            "episods: 142, score: 29\n",
            "Training Iteration:  53\n",
            "episods: 143, score: 62\n",
            "Training Iteration:  54\n",
            "episods: 144, score: 14\n",
            "Training Iteration:  55\n",
            "episods: 145, score: 27\n",
            "Training Iteration:  56\n",
            "episods: 146, score: 18\n",
            "Training Iteration:  57\n",
            "episods: 147, score: 20\n",
            "Training Iteration:  58\n",
            "episods: 148, score: 39\n",
            "Training Iteration:  59\n",
            "episods: 149, score: 70\n",
            "Training Iteration:  60\n",
            "episods: 150, score: 49\n",
            "Training Iteration:  61\n",
            "episods: 151, score: 12\n",
            "Training Iteration:  62\n",
            "episods: 152, score: 59\n",
            "Training Iteration:  63\n",
            "episods: 153, score: 54\n",
            "Training Iteration:  64\n",
            "episods: 154, score: 26\n",
            "Training Iteration:  65\n",
            "episods: 155, score: 63\n",
            "Training Iteration:  66\n",
            "episods: 156, score: 68\n",
            "Training Iteration:  67\n",
            "episods: 157, score: 29\n",
            "Training Iteration:  68\n",
            "episods: 158, score: 121\n",
            "Training Iteration:  69\n",
            "episods: 159, score: 43\n",
            "Training Iteration:  70\n",
            "episods: 160, score: 19\n",
            "Training Iteration:  71\n",
            "episods: 161, score: 32\n",
            "Training Iteration:  72\n",
            "episods: 162, score: 32\n",
            "Training Iteration:  73\n",
            "episods: 163, score: 12\n",
            "Training Iteration:  74\n",
            "episods: 164, score: 38\n",
            "Training Iteration:  75\n",
            "episods: 165, score: 78\n",
            "Training Iteration:  76\n",
            "episods: 166, score: 54\n",
            "Training Iteration:  77\n",
            "episods: 167, score: 152\n",
            "Training Iteration:  78\n",
            "episods: 168, score: 33\n",
            "Training Iteration:  79\n",
            "episods: 169, score: 35\n",
            "Training Iteration:  80\n",
            "episods: 170, score: 69\n",
            "Training Iteration:  81\n",
            "episods: 171, score: 26\n",
            "Training Iteration:  82\n",
            "episods: 172, score: 40\n",
            "Training Iteration:  83\n",
            "episods: 173, score: 20\n",
            "Training Iteration:  84\n",
            "episods: 174, score: 75\n",
            "Training Iteration:  85\n",
            "episods: 175, score: 39\n",
            "Training Iteration:  86\n",
            "episods: 176, score: 61\n",
            "Training Iteration:  87\n",
            "episods: 177, score: 24\n",
            "Training Iteration:  88\n",
            "episods: 178, score: 71\n",
            "Training Iteration:  89\n",
            "episods: 179, score: 95\n",
            "Training Iteration:  90\n",
            "episods: 180, score: 122\n",
            "Training Iteration:  91\n",
            "episods: 181, score: 62\n",
            "Training Iteration:  92\n",
            "episods: 182, score: 13\n",
            "Training Iteration:  93\n",
            "episods: 183, score: 11\n",
            "Training Iteration:  94\n",
            "episods: 184, score: 37\n",
            "Training Iteration:  95\n",
            "episods: 185, score: 34\n",
            "Training Iteration:  96\n",
            "episods: 186, score: 17\n",
            "Training Iteration:  97\n",
            "episods: 187, score: 11\n",
            "Training Iteration:  98\n",
            "episods: 188, score: 18\n",
            "Training Iteration:  99\n",
            "episods: 189, score: 26\n",
            "Training Iteration:  100\n",
            "episods: 190, score: 21\n",
            "Training Iteration:  101\n",
            "episods: 191, score: 49\n",
            "Training Iteration:  102\n",
            "episods: 192, score: 16\n",
            "Training Iteration:  103\n",
            "episods: 193, score: 96\n",
            "Training Iteration:  104\n",
            "episods: 194, score: 41\n",
            "Training Iteration:  105\n",
            "episods: 195, score: 24\n",
            "Training Iteration:  106\n",
            "episods: 196, score: 11\n",
            "Training Iteration:  107\n",
            "episods: 197, score: 14\n",
            "Training Iteration:  108\n",
            "episods: 198, score: 76\n",
            "Training Iteration:  109\n",
            "episods: 199, score: 28\n",
            "Training Iteration:  110\n",
            "episods: 200, score: 27\n",
            "Training Iteration:  111\n",
            "episods: 201, score: 70\n",
            "Training Iteration:  112\n",
            "episods: 202, score: 63\n",
            "Training Iteration:  113\n",
            "episods: 203, score: 141\n",
            "Training Iteration:  114\n",
            "episods: 204, score: 103\n",
            "Training Iteration:  115\n",
            "episods: 205, score: 10\n",
            "Training Iteration:  116\n",
            "episods: 206, score: 14\n",
            "Training Iteration:  117\n",
            "episods: 207, score: 15\n",
            "Training Iteration:  118\n",
            "episods: 208, score: 254\n",
            "Training Iteration:  119\n",
            "episods: 209, score: 11\n",
            "Training Iteration:  120\n",
            "episods: 210, score: 25\n",
            "Training Iteration:  121\n",
            "episods: 211, score: 241\n",
            "Training Iteration:  122\n",
            "episods: 212, score: 63\n",
            "Training Iteration:  123\n",
            "episods: 213, score: 90\n",
            "Training Iteration:  124\n",
            "episods: 214, score: 19\n",
            "Training Iteration:  125\n",
            "episods: 215, score: 103\n",
            "Training Iteration:  126\n",
            "episods: 216, score: 64\n",
            "Training Iteration:  127\n",
            "episods: 217, score: 122\n",
            "Training Iteration:  128\n",
            "episods: 218, score: 147\n",
            "Training Iteration:  129\n",
            "episods: 219, score: 31\n",
            "Training Iteration:  130\n",
            "episods: 220, score: 141\n",
            "Training Iteration:  131\n",
            "episods: 221, score: 90\n",
            "Training Iteration:  132\n",
            "episods: 222, score: 40\n",
            "Training Iteration:  133\n",
            "episods: 223, score: 34\n",
            "Training Iteration:  134\n",
            "episods: 224, score: 95\n",
            "Training Iteration:  135\n",
            "episods: 225, score: 35\n",
            "Training Iteration:  136\n",
            "episods: 226, score: 116\n",
            "Training Iteration:  137\n",
            "episods: 227, score: 61\n",
            "Training Iteration:  138\n",
            "episods: 228, score: 332\n",
            "Training Iteration:  139\n",
            "episods: 229, score: 125\n",
            "Training Iteration:  140\n",
            "episods: 230, score: 51\n",
            "Training Iteration:  141\n",
            "episods: 231, score: 54\n",
            "Training Iteration:  142\n",
            "episods: 232, score: 52\n",
            "Training Iteration:  143\n",
            "episods: 233, score: 498\n",
            "Training Iteration:  144\n",
            "episods: 234, score: 87\n",
            "Training Iteration:  145\n",
            "episods: 235, score: 11\n",
            "Training Iteration:  146\n",
            "episods: 236, score: 75\n",
            "Training Iteration:  147\n",
            "episods: 237, score: 102\n",
            "Training Iteration:  148\n",
            "episods: 238, score: 108\n",
            "Training Iteration:  149\n",
            "episods: 239, score: 243\n",
            "Training Iteration:  150\n",
            "episods: 240, score: 37\n",
            "Training Iteration:  151\n",
            "episods: 241, score: 95\n",
            "Training Iteration:  152\n",
            "episods: 242, score: 11\n",
            "Training Iteration:  153\n",
            "episods: 243, score: 121\n",
            "Training Iteration:  154\n",
            "episods: 244, score: 89\n",
            "Training Iteration:  155\n",
            "episods: 245, score: 68\n",
            "Training Iteration:  156\n",
            "episods: 246, score: 67\n",
            "Training Iteration:  157\n",
            "episods: 247, score: 24\n",
            "Training Iteration:  158\n",
            "episods: 248, score: 153\n",
            "Training Iteration:  159\n",
            "episods: 249, score: 14\n",
            "Training Iteration:  160\n",
            "episods: 250, score: 156\n",
            "Training Iteration:  161\n",
            "episods: 251, score: 51\n",
            "Training Iteration:  162\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-7d658e35a72e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpopulate_replayBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-9dabbd64f1bc>\u001b[0m in \u001b[0;36mpopulate_replayBuffer\u001b[0;34m(agent, env, n_episode)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0mtraining_iter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m       \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-b45eab436c13>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(self, batch_size, training_iter)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_reward\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactual_reward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                    )\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Co6B9Wf1AZpb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}